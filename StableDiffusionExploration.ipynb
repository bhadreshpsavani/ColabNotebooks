{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhadreshpsavani/ColabNotebooks/blob/master/StableDiffusionExploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6O3PFp9H8-J",
        "outputId": "683ddac0-4b32-4b57-cdf3-882b334f34b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 32548, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 32548 (delta 17), reused 22 (delta 12), pack-reused 32512\u001b[K\n",
            "Receiving objects: 100% (32548/32548), 21.24 MiB | 3.49 MiB/s, done.\n",
            "Resolving deltas: 100% (23897/23897), done.\n",
            "/content/diffusers/diffusers\n",
            "Obtaining file:///content/diffusers/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers==0.20.0.dev0) (4.6.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.0.dev0) (3.12.2)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.20.0.dev0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.0.dev0) (2.27.1)\n",
            "Collecting safetensors>=0.3.1 (from diffusers==0.20.0.dev0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.0.dev0) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.0.dev0) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.0.dev0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.0.dev0) (3.4)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.20.0.dev0-0.editable-py3-none-any.whl size=10601 sha256=19d87cd58f1e8a493973ddc0c67c0a88f45bc23e669b6d0f01bf87ae8402ab1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_o2j4ci/wheels/e2/39/95/cefa614da96e8b1ec3f962f86d335e1936336ad256d5a263b8\n",
            "Successfully built diffusers\n",
            "Installing collected packages: safetensors, huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.20.0.dev0 huggingface-hub-0.16.4 safetensors-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSSsR8U3H_7G",
        "outputId": "e1c13031-68a4-4620-ae21-fbf932f94e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/diffusers/diffusers/examples/instruct_pix2pix\n"
          ]
        }
      ],
      "source": [
        "%cd examples/instruct_pix2pix/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpOeo_WWIHHG",
        "outputId": "8b9a0e01-f343-40a8-8819-2349ab7b39af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate>=0.16.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n",
            "Collecting transformers>=4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-2.14.1-py3-none-any.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.12.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.8.5)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.41.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: tokenizers, xxhash, ftfy, dill, multiprocess, transformers, datasets, accelerate\n",
            "Successfully installed accelerate-0.21.0 datasets-2.14.1 dill-0.3.7 ftfy-6.1.1 multiprocess-0.70.15 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRJoIxgiKHya",
        "outputId": "aba065c9-aa4a-45fa-a826-77a3a62c3567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXA5rAXSIJC_",
        "outputId": "bb82706a-e168-49cf-c9f6-523e46faf22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-29 05:31:09.452408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# accelerate config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsl5wcqLIPB8"
      },
      "outputs": [],
      "source": [
        "!export MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
        "!export DATASET_ID=\"fusing/instructpix2pix-1000-samples\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCy1CT6lLj-1",
        "outputId": "b72ae242-797f-449f-f90a-95f37ad07e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jul 29 05:50:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    44W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExlgRee4ITMB",
        "outputId": "5b7c12fd-2d47-44be-cf4b-8be3b7143f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-29 05:54:21.030255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-29 05:54:27.051100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/29/2023 05:54:29 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda:0\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'sample_max_value', 'dynamic_thresholding_ratio', 'thresholding', 'variance_type', 'prediction_type', 'timestep_spacing', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "{'transformer_layers_per_block', 'time_embedding_act_fn', 'resnet_time_scale_shift', 'encoder_hid_dim_type', 'encoder_hid_dim', 'upcast_attention', 'time_embedding_dim', 'timestep_post_act', 'use_linear_projection', 'addition_embed_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'only_cross_attention', 'num_class_embeds', 'class_embeddings_concat', 'num_attention_heads', 'conv_out_kernel', 'resnet_out_scale_factor', 'mid_block_type', 'resnet_skip_time_act', 'dual_cross_attention', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'addition_time_embed_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "07/29/2023 05:54:33 - INFO - __main__ - Initializing the InstructPix2Pix UNet from the pretrained UNet.\n",
            "Downloading readme: 100% 585/585 [00:00<00:00, 5.02MB/s]\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/417M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1% 4.19M/417M [00:00<01:00, 6.87MB/s]\u001b[A\n",
            "Downloading data:   3% 12.6M/417M [00:01<00:32, 12.3MB/s]\u001b[A\n",
            "Downloading data:   5% 21.0M/417M [00:01<00:27, 14.4MB/s]\u001b[A\n",
            "Downloading data:   7% 29.4M/417M [00:02<00:25, 15.2MB/s]\u001b[A\n",
            "Downloading data:   9% 37.7M/417M [00:02<00:24, 15.7MB/s]\u001b[A\n",
            "Downloading data:  11% 46.1M/417M [00:03<00:23, 15.9MB/s]\u001b[A\n",
            "Downloading data:  13% 54.5M/417M [00:03<00:22, 15.8MB/s]\u001b[A\n",
            "Downloading data:  15% 62.9M/417M [00:04<00:21, 16.3MB/s]\u001b[A\n",
            "Downloading data:  17% 71.3M/417M [00:04<00:21, 16.3MB/s]\u001b[A\n",
            "Downloading data:  19% 79.7M/417M [00:05<00:20, 16.4MB/s]\u001b[A\n",
            "Downloading data:  21% 88.1M/417M [00:05<00:19, 16.6MB/s]\u001b[A\n",
            "Downloading data:  23% 96.5M/417M [00:06<00:19, 16.6MB/s]\u001b[A\n",
            "Downloading data:  25% 105M/417M [00:06<00:18, 16.8MB/s] \u001b[A\n",
            "Downloading data:  27% 113M/417M [00:07<00:17, 16.9MB/s]\u001b[A\n",
            "Downloading data:  29% 122M/417M [00:07<00:17, 17.0MB/s]\u001b[A\n",
            "Downloading data:  31% 130M/417M [00:08<00:17, 16.8MB/s]\u001b[A\n",
            "Downloading data:  33% 138M/417M [00:08<00:16, 16.7MB/s]\u001b[A\n",
            "Downloading data:  35% 147M/417M [00:09<00:16, 16.6MB/s]\u001b[A\n",
            "Downloading data:  37% 155M/417M [00:09<00:15, 16.8MB/s]\u001b[A\n",
            "Downloading data:  39% 164M/417M [00:10<00:15, 16.8MB/s]\u001b[A\n",
            "Downloading data:  41% 172M/417M [00:10<00:14, 16.9MB/s]\u001b[A\n",
            "Downloading data:  43% 180M/417M [00:11<00:13, 16.9MB/s]\u001b[A\n",
            "Downloading data:  45% 189M/417M [00:11<00:13, 17.1MB/s]\u001b[A\n",
            "Downloading data:  47% 197M/417M [00:12<00:12, 17.0MB/s]\u001b[A\n",
            "Downloading data:  49% 206M/417M [00:12<00:12, 16.8MB/s]\u001b[A\n",
            "Downloading data:  51% 214M/417M [00:13<00:12, 16.9MB/s]\u001b[A\n",
            "Downloading data:  53% 222M/417M [00:13<00:11, 16.8MB/s]\u001b[A\n",
            "Downloading data:  55% 231M/417M [00:14<00:11, 16.6MB/s]\u001b[A\n",
            "Downloading data:  57% 239M/417M [00:14<00:10, 16.8MB/s]\u001b[A\n",
            "Downloading data:  59% 247M/417M [00:15<00:10, 16.7MB/s]\u001b[A\n",
            "Downloading data:  61% 256M/417M [00:15<00:09, 16.9MB/s]\u001b[A\n",
            "Downloading data:  63% 264M/417M [00:16<00:09, 17.0MB/s]\u001b[A\n",
            "Downloading data:  65% 273M/417M [00:16<00:08, 16.7MB/s]\u001b[A\n",
            "Downloading data:  67% 281M/417M [00:17<00:08, 16.7MB/s]\u001b[A\n",
            "Downloading data:  69% 289M/417M [00:17<00:07, 16.6MB/s]\u001b[A\n",
            "Downloading data:  71% 298M/417M [00:18<00:07, 16.8MB/s]\u001b[A\n",
            "Downloading data:  73% 306M/417M [00:18<00:06, 16.9MB/s]\u001b[A\n",
            "Downloading data:  75% 315M/417M [00:19<00:06, 17.0MB/s]\u001b[A\n",
            "Downloading data:  77% 323M/417M [00:19<00:05, 17.0MB/s]\u001b[A\n",
            "Downloading data:  79% 331M/417M [00:20<00:05, 16.7MB/s]\u001b[A\n",
            "Downloading data:  81% 340M/417M [00:20<00:04, 16.6MB/s]\u001b[A\n",
            "Downloading data:  84% 348M/417M [00:21<00:04, 16.7MB/s]\u001b[A\n",
            "Downloading data:  86% 357M/417M [00:21<00:03, 16.8MB/s]\u001b[A\n",
            "Downloading data:  88% 365M/417M [00:22<00:03, 16.7MB/s]\u001b[A\n",
            "Downloading data:  90% 373M/417M [00:22<00:02, 16.8MB/s]\u001b[A\n",
            "Downloading data:  92% 382M/417M [00:23<00:02, 16.9MB/s]\u001b[A\n",
            "Downloading data:  94% 390M/417M [00:23<00:01, 16.9MB/s]\u001b[A\n",
            "Downloading data:  96% 398M/417M [00:24<00:01, 16.9MB/s]\u001b[A\n",
            "Downloading data:  98% 407M/417M [00:24<00:00, 16.9MB/s]\u001b[A\n",
            "Downloading data: 100% 417M/417M [00:25<00:00, 16.6MB/s]\n",
            "Downloading data files: 100% 1/1 [00:25<00:00, 25.14s/it]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1429.55it/s]\n",
            "Generating train split: 100% 1000/1000 [00:01<00:00, 693.90 examples/s]\n",
            "07/29/2023 05:55:11 - INFO - __main__ - ***** Running training *****\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Num examples = 1000\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Num Epochs = 239\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "07/29/2023 05:55:11 - INFO - __main__ -   Total optimization steps = 15000\n",
            "Steps:   0% 0/15000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
            "Steps:   0% 0/15000 [00:01<?, ?it/s, lr=5e-5, step_loss=0.353]07/29/2023 05:55:13 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
            "Steps:  33% 5000/15000 [3:02:07<6:06:02,  2.20s/it, lr=5e-5, step_loss=0.15]07/29/2023 08:57:18 - INFO - accelerate.accelerator - Saving current state to instruct-pix2pix-model/checkpoint-5000\n",
            "{'transformer_layers_per_block', 'time_embedding_act_fn', 'resnet_time_scale_shift', 'encoder_hid_dim_type', 'encoder_hid_dim', 'upcast_attention', 'time_embedding_dim', 'timestep_post_act', 'use_linear_projection', 'addition_embed_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'only_cross_attention', 'num_class_embeds', 'class_embeddings_concat', 'num_attention_heads', 'conv_out_kernel', 'resnet_out_scale_factor', 'mid_block_type', 'resnet_skip_time_act', 'dual_cross_attention', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'addition_time_embed_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "Configuration saved in instruct-pix2pix-model/checkpoint-5000/unet_ema/config.json\n",
            "Model weights saved in instruct-pix2pix-model/checkpoint-5000/unet_ema/diffusion_pytorch_model.bin\n",
            "Configuration saved in instruct-pix2pix-model/checkpoint-5000/unet/config.json\n",
            "Model weights saved in instruct-pix2pix-model/checkpoint-5000/unet/diffusion_pytorch_model.bin\n",
            "07/29/2023 08:58:04 - INFO - accelerate.checkpointing - Optimizer state saved in instruct-pix2pix-model/checkpoint-5000/optimizer.bin\n",
            "07/29/2023 08:58:04 - INFO - accelerate.checkpointing - Scheduler state saved in instruct-pix2pix-model/checkpoint-5000/scheduler.bin\n",
            "07/29/2023 08:58:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in instruct-pix2pix-model/checkpoint-5000/scaler.pt\n",
            "07/29/2023 08:58:04 - INFO - accelerate.checkpointing - Random states saved in instruct-pix2pix-model/checkpoint-5000/random_states_0.pkl\n",
            "07/29/2023 08:58:04 - INFO - __main__ - Saved state to instruct-pix2pix-model/checkpoint-5000\n",
            "Steps:  67% 10000/15000 [6:05:51<3:04:34,  2.21s/it, lr=5e-5, step_loss=0.0169]07/29/2023 12:01:02 - INFO - __main__ - 1 checkpoints already exist, removing 1 checkpoints\n",
            "07/29/2023 12:01:02 - INFO - __main__ - removing checkpoints: checkpoint-5000\n",
            "07/29/2023 12:01:04 - INFO - accelerate.accelerator - Saving current state to instruct-pix2pix-model/checkpoint-10000\n",
            "{'transformer_layers_per_block', 'time_embedding_act_fn', 'resnet_time_scale_shift', 'encoder_hid_dim_type', 'encoder_hid_dim', 'upcast_attention', 'time_embedding_dim', 'timestep_post_act', 'use_linear_projection', 'addition_embed_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'only_cross_attention', 'num_class_embeds', 'class_embeddings_concat', 'num_attention_heads', 'conv_out_kernel', 'resnet_out_scale_factor', 'mid_block_type', 'resnet_skip_time_act', 'dual_cross_attention', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'addition_time_embed_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "Configuration saved in instruct-pix2pix-model/checkpoint-10000/unet_ema/config.json\n",
            "Model weights saved in instruct-pix2pix-model/checkpoint-10000/unet_ema/diffusion_pytorch_model.bin\n",
            "Configuration saved in instruct-pix2pix-model/checkpoint-10000/unet/config.json\n",
            "Model weights saved in instruct-pix2pix-model/checkpoint-10000/unet/diffusion_pytorch_model.bin\n",
            "07/29/2023 12:01:49 - INFO - accelerate.checkpointing - Optimizer state saved in instruct-pix2pix-model/checkpoint-10000/optimizer.bin\n",
            "07/29/2023 12:01:49 - INFO - accelerate.checkpointing - Scheduler state saved in instruct-pix2pix-model/checkpoint-10000/scheduler.bin\n",
            "07/29/2023 12:01:49 - INFO - accelerate.checkpointing - Gradient scaler state saved in instruct-pix2pix-model/checkpoint-10000/scaler.pt\n",
            "07/29/2023 12:01:49 - INFO - accelerate.checkpointing - Random states saved in instruct-pix2pix-model/checkpoint-10000/random_states_0.pkl\n",
            "07/29/2023 12:01:49 - INFO - __main__ - Saved state to instruct-pix2pix-model/checkpoint-10000\n",
            "Steps:  82% 12252/15000 [7:29:05<1:40:50,  2.20s/it, lr=5e-5, step_loss=0.0263]"
          ]
        }
      ],
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\" --multi_gpu train_instruct_pix2pix.py \\\n",
        " --pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 \\\n",
        " --dataset_name=sayakpaul/instructpix2pix-1000-samples \\\n",
        " --use_ema \\\n",
        " --enable_xformers_memory_efficient_attention \\\n",
        " --resolution=512 --random_flip \\\n",
        " --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing \\\n",
        " --max_train_steps=15000 \\\n",
        " --checkpointing_steps=5000 --checkpoints_total_limit=1 \\\n",
        " --learning_rate=5e-05 --lr_warmup_steps=0 \\\n",
        " --conditioning_dropout_prob=0.05 \\\n",
        " --mixed_precision=fp16 \\\n",
        " --seed=42"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMsd6a/obIBBO9U8rrdmwJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}